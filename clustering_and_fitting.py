# -*- coding: utf-8 -*-
"""Clustering and Fitting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qyhEJTXi0kOlmRY3dHrLdy2ieJJNwNbB
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, silhouette_score

df = pd.read_csv('/content/heart.csv')

df

df .isnull().sum()

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

# Apply label encoding to each non-numeric column
for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = label_encoder.fit_transform(df[column])

plt.figure(figsize=(8, 6))
sns.countplot(x='age', data=df)
plt.title('Distribution of trestbps by AGE')
plt.xlabel('age')
plt.ylabel('trestbps')
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(x='age', y='thalach', data=data, hue='target', palette='Set2')
plt.title('Age vs Maximum Heart Rate (Thalach)')
plt.xlabel('Age')
plt.ylabel('Thalach')
plt.show()

plt.figure(figsize=(12, 6))
sns.violinplot(x='target', y='age', data=data, palette='Set2')
plt.title('Violin Plot of Age by Heart Disease Presence')
plt.xlabel('Heart Disease (0: No, 1: Yes)')
plt.ylabel('Age')
plt.show()

target_counts = data['target'].value_counts()
plt.figure(figsize=(8, 6))
plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%', colors=['skyblue', 'lightgreen'])
plt.title('Distribution of Heart Disease (0: No, 1: Yes)')
plt.show()

plt.figure(figsize=(12, 6))
sns.boxplot(x='target', y='thalach', data=data, palette='Set2')
plt.title('Box Plot of Maximum Heart Rate (Thalach) by Heart Disease Presence')
plt.xlabel('Heart Disease (0: No, 1: Yes)')
plt.ylabel('Thalach')
plt.show()

print(df.describe())

# Correlation matrix
corr_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Drop the target variable before clustering
X_clustering = df.drop(columns=['thalach'])

# Scale the features
scaler = StandardScaler()
X_scaled_clustering = scaler.fit_transform(X_clustering)

# Elbow Method to determine the optimal number of clusters
data_points = []
wcss = []

for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_scaled_clustering)
    data_points.append(kmeans.cluster_centers_)
    wcss.append(kmeans.inertia_)

# Plotting the Elbow Method
plt.plot(range(1, 11), wcss, marker='o', label='WCSS')
plt.title('Elbow Method')
plt.xlabel('Number of clusters (k)')
plt.ylabel('Within Cluster Sum of Squares (WCSS)')

for i in range(1, 11):
    plt.scatter([i] * i, wcss[:i], color='red')

plt.legend(['WCSS', 'Data Points'])
plt.show()

# Based on the Elbow Method, let's choose the optimal number of clusters (let's say 3)
kmeans = KMeans(n_clusters=3, init='k-means++', random_state=42)
df['Cluster'] = kmeans.fit_predict(X_scaled_clustering)